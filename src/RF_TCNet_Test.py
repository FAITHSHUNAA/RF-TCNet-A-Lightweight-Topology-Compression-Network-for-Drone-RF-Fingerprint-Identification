import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from RF_TCNet import RF_TCNet
import os
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import numpy as np

# Times New Roman
plt.rcParams['font.family'] = 'Times New Roman'

# Data conversion
transform = transforms.Compose([
    transforms.Resize((128, 128)),  # Resize: 128x128
    transforms.Grayscale(num_output_channels=1),
    transforms.ToTensor(),  # Convert to Tensor
    transforms.Normalize(mean=[0.5], std=[0.5])  # normalization
])

# Load the test set
test_data = datasets.ImageFolder(root=r"E:\RFa\DroneRFa\3000K_1.5_1_ALL\test", transform=transform)

# Use DataLoader for batch data loading
test_loader = DataLoader(test_data, batch_size=32, shuffle=True)

# Initialize the RF-TCNet model
model = RF_TCNet(num_classes=25)

# Move the model to the GPU (if there is one)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Load the best model
model.load_state_dict(torch.load(r'E:\RFa\solution\数据集划分\NO_ECSG_best_model.pth'))
model.eval()  # Set to evaluation mode

# Used to record the loss and accuracy during the training process
test_losses = []
test_accuracies = []

# Define the loss function
criterion = nn.CrossEntropyLoss()  # The cross-entropy loss function is used for classification tasks.

# evaluation function
def evaluate(model, test_loader, criterion, device):
    model.eval()  # Set to evaluation mode
    running_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():  # Do not calculate the gradient
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)

            # Forward propagation
            outputs = model(images)

            # Calculate the loss
            loss = criterion(outputs, labels)
            running_loss += loss.item()

            # Calculate the accuracy rate
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    avg_loss = running_loss / len(test_loader)
    accuracy = 100 * correct / total
    return avg_loss, accuracy

# Evaluate on the test dataset
test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)
print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')

# Obtain the true labels and predicted labels on the test set
all_labels = []
all_preds = []
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)
        all_labels.extend(labels.cpu().numpy())
        all_preds.extend(preds.cpu().numpy())

# Print the classification report
print("Classification Report:")
print(classification_report(all_labels, all_preds, target_names=test_data.classes))

# Confusion matrix plotting
conf_matrix = confusion_matrix(all_labels, all_preds)

# Set the size of the drawing and try to remove all the white margins.
plt.figure(figsize=(12, 6))
plt.subplots_adjust(left=0.02, right=0.98, top=0.98, bottom=0.15)

# Draw the confusion matrix and adjust the position of the gradient bar
ax = sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues",
                 xticklabels=test_data.classes, yticklabels=test_data.classes,
                 annot_kws={"size": 16, "weight": "bold", "color": "black"}, 
                 cbar=True, cbar_kws={'pad': 0.005, 'shrink': 0.5, 'aspect': 20},  # The gradient bar is extremely close and narrow.
                 linewidths=0.5, linecolor="white")

# Rotate the X-axis labels and optimize the display
plt.xticks(rotation=45, ha="right", fontsize=14)
plt.yticks(fontsize=14)

# Add axis titles and reduce the spacing
plt.xlabel('Predicted Label', fontsize=20, labelpad=5)
plt.ylabel('True Label', fontsize=20, labelpad=2)  # The spacing of the title on the left side is smaller.

# Obtain the Colorbar and adjust the font size of the scale labels
cbar = ax.collections[0].colorbar  # Obtain the Colorbar generated by the heatmap
cbar.ax.tick_params(labelsize=14)  # Set the font size of the gradient bar scale

# Automatically adjust the layout and completely remove the white borders
plt.tight_layout(pad=0.4)  # Set the pad to 0 and make it perfectly flush with the edge.
plt.savefig("confusion_matrix.png", dpi=1200, bbox_inches="tight") 
plt.show()
